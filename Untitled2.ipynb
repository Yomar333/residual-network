{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTyI22kUhfK1OBpujKlAAN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yomar333/residual-network/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0Yc_TSNGWsv",
        "outputId": "5f55f426-9425-486e-8813-b7d421529049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.5376 - loss: 0.6849 - val_accuracy: 0.6494 - val_loss: 0.6190\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7130 - loss: 0.5963 - val_accuracy: 0.7273 - val_loss: 0.5654\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7159 - loss: 0.5793 - val_accuracy: 0.7532 - val_loss: 0.5299\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7534 - loss: 0.5332 - val_accuracy: 0.8052 - val_loss: 0.5012\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7517 - loss: 0.5162 - val_accuracy: 0.8117 - val_loss: 0.4861\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7654 - loss: 0.5086 - val_accuracy: 0.8182 - val_loss: 0.4791\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7367 - loss: 0.5400 - val_accuracy: 0.7987 - val_loss: 0.4783\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7330 - loss: 0.5311 - val_accuracy: 0.7987 - val_loss: 0.4812\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7176 - loss: 0.5351 - val_accuracy: 0.7792 - val_loss: 0.4796\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7808 - loss: 0.4819 - val_accuracy: 0.8312 - val_loss: 0.4799\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7223 - loss: 0.5462 - val_accuracy: 0.7987 - val_loss: 0.4777\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7117 - loss: 0.5391 - val_accuracy: 0.7987 - val_loss: 0.4752\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7513 - loss: 0.5073 - val_accuracy: 0.7792 - val_loss: 0.4749\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7548 - loss: 0.4974 - val_accuracy: 0.7922 - val_loss: 0.4753\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7568 - loss: 0.4851 - val_accuracy: 0.8052 - val_loss: 0.4779\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7152 - loss: 0.5430 - val_accuracy: 0.8117 - val_loss: 0.4779\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7592 - loss: 0.4848 - val_accuracy: 0.8182 - val_loss: 0.4739\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7606 - loss: 0.4932 - val_accuracy: 0.8247 - val_loss: 0.4743\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7614 - loss: 0.4996 - val_accuracy: 0.8052 - val_loss: 0.4744\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7586 - loss: 0.4883 - val_accuracy: 0.7792 - val_loss: 0.4758\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7467 - loss: 0.5126 - val_accuracy: 0.7857 - val_loss: 0.4743\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7495 - loss: 0.5079 - val_accuracy: 0.8312 - val_loss: 0.4777\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7494 - loss: 0.5095 - val_accuracy: 0.7792 - val_loss: 0.4783\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7493 - loss: 0.5036 - val_accuracy: 0.7922 - val_loss: 0.4793\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7583 - loss: 0.5064 - val_accuracy: 0.7987 - val_loss: 0.4766\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7700 - loss: 0.5127 - val_accuracy: 0.8052 - val_loss: 0.4768\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7483 - loss: 0.5202 - val_accuracy: 0.7987 - val_loss: 0.4763\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7494 - loss: 0.4992 - val_accuracy: 0.7857 - val_loss: 0.4763\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7561 - loss: 0.4950 - val_accuracy: 0.7987 - val_loss: 0.4745\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7621 - loss: 0.4956 - val_accuracy: 0.7857 - val_loss: 0.4766\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7644 - loss: 0.5153 - val_accuracy: 0.8052 - val_loss: 0.4773\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7694 - loss: 0.4518 - val_accuracy: 0.8117 - val_loss: 0.4764\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7460 - loss: 0.5039 - val_accuracy: 0.7792 - val_loss: 0.4774\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7584 - loss: 0.5190 - val_accuracy: 0.7792 - val_loss: 0.4768\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7623 - loss: 0.4846 - val_accuracy: 0.7922 - val_loss: 0.4786\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7440 - loss: 0.4895 - val_accuracy: 0.7857 - val_loss: 0.4811\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7534 - loss: 0.4812 - val_accuracy: 0.7792 - val_loss: 0.4820\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7831 - loss: 0.4812 - val_accuracy: 0.7662 - val_loss: 0.4813\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7381 - loss: 0.4984 - val_accuracy: 0.7792 - val_loss: 0.4797\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7472 - loss: 0.5046 - val_accuracy: 0.7857 - val_loss: 0.4902\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7525 - loss: 0.5181 - val_accuracy: 0.7922 - val_loss: 0.4879\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7308 - loss: 0.5254 - val_accuracy: 0.7857 - val_loss: 0.4861\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7408 - loss: 0.4966 - val_accuracy: 0.7922 - val_loss: 0.4843\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7762 - loss: 0.4825 - val_accuracy: 0.7597 - val_loss: 0.4866\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7822 - loss: 0.4672 - val_accuracy: 0.7792 - val_loss: 0.4859\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7551 - loss: 0.4946 - val_accuracy: 0.7662 - val_loss: 0.4850\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7737 - loss: 0.4856 - val_accuracy: 0.7662 - val_loss: 0.4836\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8014 - loss: 0.4408 - val_accuracy: 0.7857 - val_loss: 0.4845\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7670 - loss: 0.4709 - val_accuracy: 0.7662 - val_loss: 0.4857\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7401 - loss: 0.4955 - val_accuracy: 0.7792 - val_loss: 0.4859\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7532 - loss: 0.4967 \n",
            "Test Accuracy: 0.7792\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "[[84 15]\n",
            " [19 36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83        99\n",
            "           1       0.71      0.65      0.68        55\n",
            "\n",
            "    accuracy                           0.78       154\n",
            "   macro avg       0.76      0.75      0.76       154\n",
            "weighted avg       0.78      0.78      0.78       154\n",
            "\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7532 - loss: 0.4967 \n",
            "Test Accuracy: 0.7792\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "[[84 15]\n",
            " [19 36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83        99\n",
            "           1       0.71      0.65      0.68        55\n",
            "\n",
            "    accuracy                           0.78       154\n",
            "   macro avg       0.76      0.75      0.76       154\n",
            "weighted avg       0.78      0.78      0.78       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Load dataset\n",
        "url = 'https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Display first few rows\n",
        "data.head()\n",
        "# Check for missing values\n",
        "data.isnull().sum()\n",
        "\n",
        "# Separate features and target\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for CNN input\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add convolutional layer\n",
        "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "\n",
        "# Add pooling layer\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Add dropout for regularization\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Flatten the output\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Predict the labels\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Predict the labels\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Confusion matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECMvLAKLPk6f",
        "outputId": "2569d924-b6de-47a4-b3e9-df23b3332078"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT0FX_s7ROHH",
        "outputId": "e8eaa34d-93a2-43df-cb02-6eca57664592"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "'1_Kaplan_SAT_Premier_2017_Introdution_and_Math (1).pdf'\n",
            " 1_Kaplan_SAT_Premier_2017_Introdution_and_Math.pdf\n",
            "'2023-12-18 14-12-21.mkv'\n",
            "'2023-12-20 20-07-56.mkv'\n",
            " antenna\n",
            "'antenna c6 p1.mp4'\n",
            "'antenna c6 p2.mp4'\n",
            "'Antenna Module.zip'\n",
            "'assigment 1'\n",
            "'Aug.17 (1).pdf'\n",
            " Aug.17.pdf\n",
            " barrons\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'c project'\n",
            " dc\n",
            "'Document from aomar53057 (1).pdf'\n",
            "'Document from aomar53057 (2).pdf'\n",
            "'Document from aomar53057 copy.pdf'\n",
            "'Document from aomar53057.pdf'\n",
            "'folder 7'\n",
            "'iBooks copy (1).pdf'\n",
            "'iBooks copy.pdf'\n",
            " kaplan\n",
            "'KAPLAN 2017 (1).pdf'\n",
            "'KAPLAN 2017 (2).pdf'\n",
            "'KAPLAN 2017 (3).pdf'\n",
            "'KAPLAN 2017.pdf'\n",
            " lab2.mp4\n",
            " MARCH-USA-2018-compressed-1.pdf\n",
            "'May 2017-4.pdf'\n",
            "'mc_ch14 (1).ppt'\n",
            "'mc_ch14 (1).ppt.gslides'\n",
            "'mc_ch14 (2).ppt.gslides'\n",
            "'mc_ch14 (3).ppt.gslides'\n",
            "'mc_ch14 (4).ppt.gslides'\n",
            "'mc_ch14 (5).ppt.gslides'\n",
            " mc_ch14.ppt\n",
            " mc_ch14.ppt.gslides\n",
            "'mc graw hill'\n",
            " mcgraw-hill_education_sat_2017_700p.pdf\n",
            " news\n",
            "'news (1)'\n",
            "'Nov 2017 SAT (1).pdf'\n",
            "'Nov 2017 SAT (2).pdf'\n",
            "'Nov 2017 SAT.pdf'\n",
            "'omar_ahmed_CV (1).pdf'\n",
            " omar_ahmed_CV.pdf\n",
            "'omar ahmed  id 193516  video (1).pptx'\n",
            "'omar ahmed  id 193516  video.pptx'\n",
            "'omar amit july.rar'\n",
            "'omar maadi 503'\n",
            " photos\n",
            " princeton\n",
            "'princeton (1)'\n",
            "\"Reader's Digest+USA-2017-06 copy.pdf\"\n",
            " schedule\n",
            "'Screenshot_20180213-162754 (1).png'\n",
            " Screenshot_20180213-162754.png\n",
            "'Social media (1).docx'\n",
            "'Social media (1).docx.gdoc'\n",
            "'Social media (1).gdoc'\n",
            "'Social media.docx'\n",
            "'Social media.docx.gdoc'\n",
            "'Social media.gdoc'\n",
            "'STRATEGY & PRACTICE GUIDE 2016 - (1).pdf'\n",
            "'STRATEGY & PRACTICE GUIDE 2016 -.pdf'\n",
            " ukkkk\n",
            "'uk trip'\n",
            "'Untitled folder'\n",
            "'Untitled folder (1)'\n",
            "'Untitled folder (2)'\n",
            "'Untitled folderom'\n",
            "'WhatsApp Image 2020-11-17 at 6.50.13 PM (1).jpeg'\n",
            "'WhatsApp Image 2020-11-17 at 6.50.13 PM.jpeg'\n",
            "'WhatsApp Image 2024-06-27 at 4.36.14 PM (4).jpeg'\n",
            " wireless\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import lite\n",
        "import tensorflow as tf\n",
        "# load and evaluate a saved model\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "from PIL import ImageEnhance\n",
        "import io\n",
        "import numpy as np\n",
        "from keras.layers import Input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D,MaxPooling2D\n",
        "from keras.layers import Dense,Flatten,SpatialDropout2D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.callbacks import History\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import r2_score, roc_auc_score, roc_curve\n",
        "from scipy import stats  # For in-built method to get PCC\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "class Diabatic_Retino_Detection():\n",
        "    def __init__(self, dataset_path=\"/content/drive/MyDrive/retinopathy-dataset\",enhanceddataset_path=\"/content/drive/MyDrive/newretinopathy-dataset\",data_path=\"/content/drive/MyDrive/\",models_path=\"'/content/drive/MyDrive/model/'\"):\n",
        "        self.dataset_path  = dataset_path\n",
        "        self.enhanceddataset_path=enhanceddataset_path\n",
        "        self.models_path=models_path\n",
        "        self.data_path=data_path\n",
        "        self.predictionsclasses = ['nosymptoms', 'symptoms']\n",
        "\n",
        "#---------------Image acquisition per image---------- details: it read image and convert it into digital , do shaping and resizing etc.\n",
        "    def image_acquisition(self,image_file, gray_scale=False):\n",
        "        image_src= cv2.imread( image_file)\n",
        "        if gray_scale:\n",
        "          image_rgb = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "          image_rgb = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
        "        TARGET_PIXEL_AREA = 100000.0\n",
        "        img=image_rgb\n",
        "        ratio = float(img.shape[1]) / float(img.shape[0])\n",
        "        new_h = int(math.sqrt(TARGET_PIXEL_AREA / ratio) + 0.5)\n",
        "        new_w = int((new_h * ratio) + 0.5)\n",
        "        img2 = cv2.resize(img, (new_w,new_h))\n",
        "        return img2\n",
        "\n",
        "#---------------Image enhance contrast per image---------- details: it it enhance the contrast in per image it is a sub function of function mentioned below this function etc.\n",
        "    def enhance_contrast(self,image_matrix, bins=256):\n",
        "        image_flattened = image_matrix.flatten()\n",
        "        image_hist = np.zeros(bins)\n",
        "\n",
        "        # frequency count of each pixel\n",
        "        for pix in image_matrix:\n",
        "            image_hist[pix] += 1\n",
        "\n",
        "        # cummulative sum\n",
        "        cum_sum = np.cumsum(image_hist)\n",
        "        norm = (cum_sum - cum_sum.min()) * 255\n",
        "        # normalization of the pixel values\n",
        "        n_ = cum_sum.max() - cum_sum.min()\n",
        "        uniform_norm = norm / n_\n",
        "        uniform_norm = uniform_norm.astype('int')\n",
        "\n",
        "        # flat histogram\n",
        "        image_eq = uniform_norm[image_flattened]\n",
        "        # reshaping the flattened matrix to its original shape\n",
        "        image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
        "\n",
        "        return image_eq\n",
        "\n",
        "#---------------Image equalize per image---------- details: it it enhance and equalize per image and preprocess it for next step of reshaping for dataset etc.\n",
        "    def equalize_this(self,image_file,saveimage_file, with_plot=False, gray_scale=False, bins=256):\n",
        "        image_src = self.image_acquisition(image_file, gray_scale=False)\n",
        "        if not gray_scale:\n",
        "            r_image = image_src[:, :, 0]\n",
        "            g_image = image_src[:, :, 1]\n",
        "            b_image = image_src[:, :, 2]\n",
        "\n",
        "            r_image_eq = self.enhance_contrast(image_matrix=r_image)\n",
        "            g_image_eq = self.enhance_contrast(image_matrix=g_image)\n",
        "            b_image_eq = self.enhance_contrast(image_matrix=b_image)\n",
        "\n",
        "            image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
        "            cmap_val = None\n",
        "        else:\n",
        "            image_eq = self.enhance_contrast(image_matrix=image_src)\n",
        "            cmap_val = 'gray'\n",
        "\n",
        "        #if with_plot:\n",
        "        fig = plt.figure(figsize=(10, 20))\n",
        "\n",
        "        #ax1 = fig.add_subplot(2, 2, 1)\n",
        "        #ax1.axis(\"off\")\n",
        "        #ax1.title.set_text('Original')\n",
        "        #ax2 = fig.add_subplot(2, 2, 2)\n",
        "        #ax2.axis(\"off\")\n",
        "        #ax2.title.set_text(\"Equalized\")\n",
        "\n",
        "        #ax1.imshow(image_src, cmap=cmap_val)\n",
        "        #ax2.imshow(image_eq, cmap=cmap_val)\n",
        "        plt.imsave(saveimage_file, np.uint8(image_eq), cmap=cmap_val)\n",
        "                    # load the image\n",
        "        image = Image.open(saveimage_file)\n",
        "            # convert image to numpy array\n",
        "        data = np.asarray(image)\n",
        "        #print(type(data))\n",
        "            # summarize shape\n",
        "        #print(data.shape)\n",
        "\n",
        "            # create Pillow image\n",
        "        image2 = Image.fromarray(data)\n",
        "        #print(type(image2))\n",
        "\n",
        "        # summarize image details\n",
        "        #print(image2.mode)\n",
        "        #print(image2.size)\n",
        "        #print(type(image2))\n",
        "        #img = Image.open(fh, mode='r')\n",
        "        roi_img = image2\n",
        "\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        roi_img.save(img_byte_arr, format='jpeg')\n",
        "        img_byte_arr = img_byte_arr.getvalue()\n",
        "        #print(type(img_byte_arr))\n",
        "        return img_byte_arr\n",
        "\n",
        "#---------------Image reshaping per image---------- details: it reshape the image array to store in dataset.\n",
        "    def image_reshaping(self,image):\n",
        "        #new_im = Image.fromarray(image)\n",
        "        new_im = np.array(image)\n",
        "        return new_im\n",
        "\n",
        "#---------------Imagedata preprocessing ---------- details: this function convert all the input dataset images into enhance images and save image arrays of byte and extract labels and save them into .\n",
        "    def imagedata_preprocessing(self):\n",
        "        print(\"Image Data preprocessing started...\")\n",
        "        print(\"Image Data acquisition started...\")\n",
        "        # preprocessing\n",
        "        imgs_path = self.dataset_path\n",
        "        data = []\n",
        "        labels = []\n",
        "        labelclasses = os.listdir(imgs_path)\n",
        "        for labelclass in labelclasses:\n",
        "            img_path = os.path.join(imgs_path, str(labelclass))  # 0-42\n",
        "            saveimg_path = os.path.join(self.enhanceddataset_path, str(labelclass))  # 0-42\n",
        "            imgs =os.listdir(img_path)\n",
        "            for img in imgs:\n",
        "                image_file=img_path+'/'+img\n",
        "                saveimagefile=saveimg_path+'/'+img\n",
        "                #image_file=os.path.join(imgs_path, img)\n",
        "                image_eq=self.equalize_this(image_file,saveimagefile, with_plot=False, gray_scale=False, bins=256)\n",
        "                im = self.image_reshaping(image_eq)\n",
        "                data.append(im)\n",
        "                labels.append(labelclass)\n",
        "                print('label',labelclass,'filename',img)\n",
        "        print(\"Image Data successfully preprocessed\")\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "#---------------Imagedata preprocessing ---------- details:this function convert imagedataset array return by preprocessing funtion into numpy array and change the categorical labels into numeric this process is called transformation of data for modeling purpose.\n",
        "    def imagedata_transformation(self):\n",
        "        #print(self.data)\n",
        "        #x_train= np.asarray(self.data)\n",
        "        #y_train = np.asarray(self.labels)\n",
        "        #print(\"training shape: \", x_train.shape, y_train.shape)\n",
        "        #le = preprocessing.LabelEncoder()\n",
        "        #y_train=le.fit_transform(y_train)\n",
        "        #self.x_train= x_train\n",
        "        #self.y_train=y_train\n",
        "        train_data_path = self.enhanceddataset_path\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                      rotation_range=40,\n",
        "                                      width_shift_range=0.2,\n",
        "                                      height_shift_range=0.2,\n",
        "                                      shear_range=0.2,\n",
        "                                      zoom_range=0.2,\n",
        "                                      validation_split=0.2,\n",
        "                                      horizontal_flip=True,\n",
        "                                      fill_mode='nearest')\n",
        "        training_data = train_datagen.flow_from_directory(train_data_path,\n",
        "                                      target_size=(150,150),\n",
        "                                      batch_size=32,\n",
        "                                      class_mode='binary',\n",
        "                                      subset='training')\n",
        "        valid_data = train_datagen.flow_from_directory(train_data_path,\n",
        "                                      target_size=(150,150),\n",
        "                                      batch_size=32,\n",
        "                                      class_mode='binary',\n",
        "                                      subset='validation')\n",
        "\n",
        "        for i in os.listdir(train_data_path):\n",
        "          print(str(len(os.listdir(train_data_path+'/'+i))) +\" \"+ i +\" images\")\n",
        "\n",
        "        self.training_data=training_data\n",
        "        self.valid_data=valid_data\n",
        "        self.valid_datax=valid_data[0][0]\n",
        "        self.valid_datalabels= valid_data.labels\n",
        "        self.valid_dataclasses= valid_data.class_indices.keys()\n",
        "        #print(valid_data[0][0])\n",
        "        print('Image data transformation done successfully.')\n",
        "\n",
        "#---------------CNN Model configration---------- details: this function is about model configuration in which we set model checkpoints set number of epochs number of layers and type of layer number of outputs and number of iterations in model and model path .\n",
        "    def model_configration(self):\n",
        "        image_size = (64, 64)\n",
        "        print(\"Convolutional Model configration started...\")\n",
        "        model_path = self.models_path+'test.h5'\n",
        "        print(model_path)\n",
        "        model = keras.models.Sequential([\n",
        "                                    keras.layers.Conv2D(filters=32, kernel_size=3, input_shape=[150, 150, 3]),\n",
        "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                                    keras.layers.Conv2D(filters=64, kernel_size=3),\n",
        "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                                    keras.layers.Conv2D(filters=128, kernel_size=3),\n",
        "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                                    keras.layers.Conv2D(filters=256, kernel_size=3),\n",
        "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "                                    keras.layers.Dropout(0.5),\n",
        "                                    keras.layers.Flatten(),\n",
        "                                    keras.layers.Dense(units=128, activation='relu'),\n",
        "                                    keras.layers.Dropout(0.1),\n",
        "                                    keras.layers.Dense(units=256, activation='relu'),\n",
        "                                    keras.layers.Dropout(0.25),\n",
        "                                    keras.layers.Dense(units=2, activation='softmax') ])\n",
        "        model.compile(optimizer = Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.summary()\n",
        "        print(\"Convolutional Model successfully configured.\")\n",
        "        self.model=model\n",
        "#---------------CNN model Performance graph---------- details: this function is about  for performance and evaluation graphs .\n",
        "    def plot_model_history(self,history):\n",
        "        #history=self.history\n",
        "        print(history.history.keys())\n",
        "        # summarize history for accuracy\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "#---------------model testing performance graphs---------- details: this function test image after enhancing and show the labels .\n",
        "    def results(self,target_test, predicted_test,ModelName,labels):\n",
        "       target_names = labels\n",
        "       print(classification_report(target_test, predicted_test, target_names=target_names))\n",
        "       y_test = target_test\n",
        "       preds = predicted_test\n",
        "       rms = np.sqrt(np.mean(np.power((np.array(y_test) - np.array(preds)), 2)))\n",
        "       score = r2_score(y_test, preds)\n",
        "       mae = mean_absolute_error(y_test, preds)\n",
        "       mse = mean_squared_error(y_test, preds)\n",
        "       pearson_coef, p_value = stats.pearsonr(y_test, preds)\n",
        "\n",
        "       print(\"root mean square:\", rms)\n",
        "       print(\"score:\", score)\n",
        "       print(\"mean absolute error:\", mae)\n",
        "       print(\"mean squared error:\", mse)\n",
        "       print(\"pearson_coef:\", pearson_coef)\n",
        "       print(\"p_value:\", p_value)\n",
        "       print(\"=======================================================================\\n\\n\")\n",
        "       skplt.metrics.plot_confusion_matrix(\n",
        "        y_test,\n",
        "        preds,\n",
        "        figsize=(10, 6), title=\"Confusion matrix\\n Deposite Category \"+ModelName)\n",
        "       plt.xlim(-0.5, len(np.unique(y_test)) - 0.5)\n",
        "       plt.ylim(len(np.unique(y_test)) - 0.5, -0.5)\n",
        "       plt.savefig('cvroc.png')\n",
        "       plt.show()\n",
        "\n",
        "#---------------CNN model training---------- details: this function is about training model by giving input training dataset and labels which we got from above funcitons and set validation ratio 0.2 for performance and evaluation .\n",
        "    def train_model(self):\n",
        "        print(\"Convolutional Model training started...\")\n",
        "        training_data=self.training_data\n",
        "        valid_data=self.valid_data\n",
        "        model= self.model\n",
        "        history = History()\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=5),ModelCheckpoint(filepath=self.models_path+'best_model.h5', monitor='val_loss', save_best_only=True),history]\n",
        "        history = model.fit_generator(training_data,\n",
        "                                      steps_per_epoch = 8000/32,\n",
        "                                      epochs = 1000,\n",
        "                                      validation_data = valid_data,\n",
        "                                      validation_steps = 64,\n",
        "                                      use_multiprocessing = True,\n",
        "                                      workers = 8,\n",
        "                                      callbacks=callbacks)\n",
        "\n",
        "        self.plot_model_history(history)\n",
        "        model.save(self.models_path+'model.hd5')\n",
        "        print(\"Convolutional Model successfully trained.\")\n",
        "        print(\"Convolutional Model Performance & testing results\")\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "        self.history=history\n",
        "        test_datax= self.valid_datax\n",
        "        predicted_test=model.fit(test_datax)\n",
        "        target_test=self.valid_datalabels\n",
        "        ModelName= \"Convolutional Neural Network\"\n",
        "        labels=self.valid_dataclasses\n",
        "        self.results(target_test, predicted_test,ModelName,labels)\n",
        "\n",
        "    def train_previousmodel(self):\n",
        "        print(\"Convolutional Model training started...\")\n",
        "        model_path='/content/drive/MyDrive/model/model.hd5'\n",
        "        model = load_model(model_path)\n",
        "        training_data=self.training_data\n",
        "        valid_data=self.valid_data\n",
        "        #model= self.model\n",
        "        history = History()\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=5),ModelCheckpoint(filepath=self.models_path+'best_model.h5', monitor='val_loss', save_best_only=True),history]\n",
        "        history = model.fit_generator(training_data,\n",
        "                                      steps_per_epoch = 8000/32,\n",
        "                                      epochs = 1000,\n",
        "                                      validation_data = valid_data,\n",
        "                                      validation_steps = 64,\n",
        "                                      use_multiprocessing = True,\n",
        "                                      workers = 8,\n",
        "                                      callbacks=callbacks)\n",
        "\n",
        "        self.plot_model_history(history)\n",
        "        model.save(model_path)\n",
        "        history\n",
        "        print(\"Convolutional Model successfully trained.\")\n",
        "        print(\"Convolutional Model Performance & testing results\")\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "        self.history=history\n",
        "        test_datax= self.valid_datax\n",
        "        predicted_test=model.fit(test_datax)\n",
        "        target_test=self.valid_datalabels\n",
        "        ModelName= \"Convolutional Neural Network\"\n",
        "        labels=self.valid_dataclasses\n",
        "        self.results(target_test, predicted_test,ModelName,labels)\n",
        "#---------------hd5 model to tf lite model conversion---------- details: this function converts the model into tf lite version for lite applications .\n",
        "    def convert_hd5model_to_tflite(self):\n",
        "        print(\"Convolutional Model conversion from to tflite started...\")\n",
        "        models = tf.keras.models.load_model('/content/drive/MyDrive/model/model.hd5')\n",
        "        converter = lite.TFLiteConverter.from_keras_model(models)\n",
        "        print(converter)\n",
        "        model = converter.convert()\n",
        "        tfmodel_path=self.models_path+'model.tflite'\n",
        "        assert isinstance(model, object)\n",
        "        file = open(tfmodel_path, 'wb').write(model)\n",
        "        print(\"Convolutional Model successfully converted from to tflite...\")\n",
        "\n",
        "#---------------model testing---------- details: this function test image after enhancing and show the labels .\n",
        "    def test_model(self,Image_test_path):\n",
        "        print(\"Image testing started...\")\n",
        "        # load model\\\n",
        "        model_path=self.models_path+'model.hd5'\n",
        "        model = load_model(model_path)\n",
        "        # summarize model.\n",
        "        # model.summary()\n",
        "        # load dataset\n",
        "        image1 = image.load_img(Image_test_path, target_size=(150, 150))\n",
        "        image1.save('test.jpeg')\n",
        "        # image1\n",
        "        #input_arr = image.img_to_array(image1)\n",
        "        image1=self.equalize_this('test.jpeg','test.jpeg' , with_plot=False, gray_scale=False, bins=256)\n",
        "        input_arr = self.image_reshaping(image1) # Convert single image to a batch\n",
        "        #input_arr = image.img_to_array(input_arr)\n",
        "        #input_arr\n",
        "        predictions1 = model.predict(input_arr)\n",
        "        print(predictions1)\n",
        "        probabilities1 = model.predict_proba(input_arr)\n",
        "        print(probabilities1)\n",
        "        predictionsclasses = self.predictionsclasses\n",
        "        probabilitiestest = list(probabilities1)\n",
        "        testprob = max(probabilitiestest)\n",
        "        print(testprob.tolist())\n",
        "        max_value = max(testprob)\n",
        "        print(max_value)\n",
        "        for i in range(len(testprob)):\n",
        "            if testprob[i] == max_value:\n",
        "                max_index = i\n",
        "                print(predictionsclasses[max_index])\n",
        "        print(\"Image testing successfully completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Diabatic_Retino_Detection = Diabatic_Retino_Detection()\n",
        "    #Diabatic_Retino_Detection.imagedata_preprocessing()\n",
        "    Diabatic_Retino_Detection.imagedata_transformation()\n",
        "    Diabatic_Retino_Detection.model_configration()\n",
        "    Diabatic_Retino_Detection.train_model()\n",
        "    #Diabatic_Retino_Detection.train_previousmodel()\n",
        "    Image_test1 = '/content/drive/MyDrive/retinopathy-dataset/nosymptoms/10265_left.jpeg'\n",
        "    Image_test2 = '/content/drive/MyDrive/retinopathy-dataset/nosymptoms/10643_left.jpeg'\n",
        "    Image_test3 = '/content/drive/MyDrive/retinopathy-dataset/symptoms/10030_left.jpeg'\n",
        "    Image_test4 = '/content/drive/MyDrive/retinopathy-dataset/symptoms/10030_right.jpeg'\n",
        "    Diabatic_Retino_Detection.test_model(Image_test1)\n",
        "    Diabatic_Retino_Detection.test_model(Image_test2)\n",
        "    Diabatic_Retino_Detection.test_model(Image_test3)\n",
        "    Diabatic_Retino_Detection.test_model(Image_test4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "kAe4jQFmRSFB",
        "outputId": "00504316-91b0-4b90-dc67-0c678cf434cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dc35b828de5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras tensorflow --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wsCEVyYcYjcu",
        "outputId": "326ba91a-f222-4798-a540-a2fe61392630"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ml-dtypes (from keras)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Downloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m822.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.9.0 ml-dtypes-0.5.1 tensorboard-2.19.0 tensorflow-2.19.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "ml_dtypes",
                  "tensorflow"
                ]
              },
              "id": "ae876f5763d741538d0089feab6a327d"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}